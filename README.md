# 📄 RAG Document Q&A with Groq + Llama3 + Streamlit

This project implements a Retrieval-Augmented Generation (RAG) system that allows you to query research papers using Groq’s Llama3 model with a FAISS vector database for document retrieval. It is built with LangChain, Streamlit, and OpenAI embeddings for semantic search.

🚀 Features

- Upload and process multiple PDF research papers.

- Split documents into chunks for better embedding and retrieval.

- Store embeddings in a FAISS vector store.

- Query research papers with natural language questions.

- Get context-aware answers generated by Groq’s Llama3-8b-8192 model.

- Inspect retrieved document chunks with a Streamlit expander.

🛠️ Tech Stack

LangChain
 – Document loading, splitting, vector DB, and retrieval.

Groq
 – For running the Llama3 LLM.

OpenAI Embeddings
 – For semantic vector representation.

FAISS
 – Vector store for efficient similarity search.

Streamlit
 – Interactive UI for querying documents.

PyPDFDirectoryLoader
 – For loading research papers.

📂 Project Structure
.
├── research_papers/         # Directory containing PDF research papers
├── app.py                   # Main Streamlit app (your provided code)
├── requirements.txt         # Python dependencies
└── README.md                # Project documentation

⚙️ Setup & Installation

Clone this repo

```bash
git clone https://github.com/RAG_based_Q-A_Chatbot.git
cd RAG_based_Q-A_Chatbot
```

Create a virtual environment & install dependencies
```bash
pip install -r requirements.txt
```

Add your API Keys
Create a .env file in the root directory and add:

```bash
OPENAI_API_KEY=your_openai_api_key
GROQ_API_KEY=your_groq_api_key
```

Place research papers
Put your PDF research papers in the research_papers/ folder.

Run the Streamlit app

```bash
streamlit run app.py
```

📌 Usage

Click "Document Embedding" to build the FAISS vector database.

Enter a query in the input box (e.g., "What is the main contribution of this paper?").

Get answers based on document context.

Expand the "Document similarity Search" panel to see the actual text chunks used.

⏱️ Example Workflow

Upload 50+ PDF research papers.

Ask: “What methods are used for improving NLP embeddings?”

The app retrieves the most relevant sections and Llama3 answers based only on that context.

✅ Requirements

Python 3.9+

Streamlit

LangChain

FAISS

OpenAI + Groq API keys

(Ensure they are added in requirements.txt)

📜 License

This project is licensed under the MIT License – feel free to use, modify, and distribute.
